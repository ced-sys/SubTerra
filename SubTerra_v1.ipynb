{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuQ39C2D3tUvOTbU3XcUsy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ced-sys/SubTerra/blob/main/SubTerra_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tiXFhIX01D9h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from xgboost import XGBClassifier\n",
        "  XGBOOST_AVAILABLE=True\n",
        "except ImportError:\n",
        "  XGBOOST_AVAILABLE=False\n",
        "  print(\"Warning: XGBoost not available. Install with: pip install xgboost\")"
      ],
      "metadata": {
        "id": "sDA2s8Dn2Gp8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model={}\n",
        "X_train=None\n",
        "X_test=None\n",
        "y_train=None\n",
        "y_test=None\n",
        "feature_names=None\n",
        "scaler=StandardScaler()"
      ],
      "metadata": {
        "id": "lWEo9fi05cla"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(filepath='/content/training_dataset.csv'):\n",
        "  global feature_names\n",
        "\n",
        "  try:\n",
        "    print(f\"Loading dataset from: {filepath}\")\n",
        "    df=pd.read_csv(filepath)\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "\n",
        "    #Remove non-feature columns\n",
        "    drop_cols=[col for col in df.columns\n",
        "               if any (keyword in col.lower()\n",
        "               for keyword in ['fid', 'path', 'layer', 'id'])]\n",
        "\n",
        "    if drop_cols:\n",
        "      print(f\"Dropping columns: {drop_cols}\")\n",
        "      df_cleaned=df.drop(columns=drop_cols)\n",
        "    else:\n",
        "      df_cleaned=df.copy()\n",
        "\n",
        "    #Separate features and labels\n",
        "    if 'label' not in df_cleaned.columns:\n",
        "      raise ValueError(\"No 'label' column found in dataset\")\n",
        "\n",
        "    X=df_cleaned.drop(columns=['label'])\n",
        "    y=df_cleaned['label']\n",
        "\n",
        "    #convert to numeric and handle missing values\n",
        "    X=X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    #Handle missing values\n",
        "    missing_counts=X.isnull().sum()\n",
        "    if missing_counts.any():\n",
        "      print(f\"Missing values found: {missing_counts[missing_counts>0]}\")\n",
        "      X=X.fillna(X.median())\n",
        "\n",
        "    feature_names=list(X.columns)\n",
        "    print(f\"Features: {len(feature_names)}\")\n",
        "    print(f\"Label distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "  except FileNotFoundError:\n",
        "    raise FileNotFoundError(f\"Dataset file not found: {filepath}\")\n",
        "  except Exception as e:\n",
        "    raise Exception(f\"Error loading dataset: {str(e)}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HdQVhIuP5out"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ofrt9WQl9tcr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}